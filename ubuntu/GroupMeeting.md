#### 组会纪录

- **6.8**

  ```python
  1.固定在车子的正前方，利用识别到的三维框计算正前方位置，首先飞到静止的车辆前方，起始位置在手上或者地上，不一定要绕车飞一圈重建三维场景；
  2.首先在仿真软件中控制无人机的飞行，新建场景以及测试无人机的控制；
  ```
  
- **6.24**

  ```python
  1.针对混合模型准确度不高的情况，采用数据增强方法，当达到与原始模型准确度差不多的情况时，再与添加进自己模型的情况进行对比；
  2.进行纯样本训练，对样本数据 其他仿真车辆进行检测
  3.再次检测与纪录样本标签是否准确，进行标记
  4.无人机可以直接飞到指定位置，实现实时追踪，善于使用多线程进行开发
  ```

- **7.1(前三周见AirSImRecord.md)**

  ```python
  # 7.1
  1.采取一定半径范围内一定高度范围的样本数据，扩大样本数据到一万左右，将路线提前定义好进行飞行采集，防止相机抖动，同时检查相机抖动的原因；
  2.标签再检查，防止微调；
  3.数据增强尝试，将图片旋转并改变label的某些值；
  4.将车的模型导入到3D软件中进行建模，使用相机进行录制也可以，取消无人机的操作可能可以增加数据的准确率，固定车子的角度改变相机距离等；
  5.输出smoke训练准确度，再读SMOKE训练代码；
  ```

- **7.8**

  ```python
  # 7.8
  1.解决无人机自旋问题，切向速度与径向速度的比值，降低无人机飞行速度主要是绕圆速度
  2.3米高度采集3179张样本，但标签暂时未解决，首先改内参，再试高度以及图片保存格式问题
  
  # 7.12
  与UE4的x轴夹角-顺           与label的x轴夹角-顺
  车辆右侧：0°                alpha：0        向右   平移实际需要90
  车辆后侧：90°               alpha：-90      向前   平移实际需要0
  车辆左侧  180°              alpha：±180     向左   平移实际需要-90或者270
  车辆前侧：-90°               alpha：90      向后    平移实际需要180
  -75                               75             平移实际需要75+90
  采完不同高度的螺旋数据集以后，在车子四周左右平移采了一千不到的样本集，在制作标签时发现x数据十分混乱，使用pycharm进行debug以后发现在旋转矩阵处出现错误，经过四周的试验过程，改出了最终版-sin,-cos,cos,-sin，然后斜着平移以后验证效果也是正确的，接着为了证明这个矩阵，进行推导见笔记本，证明正确，因为alpha是车子正方向相对于相机坐标系x轴的顺时针旋转，旋转角theta也是顺时针，所以两者的差值为90度
  
  ```
  
- **7.15**

  ```python
  # 7.15
  根据修改完后的create_datasets.py重新采集数据，在初始3m高度采集不同圆心的四次轨迹，同时升高1.7m继续采集四次轨迹的数据，最终将之前的所有数据集以及本次采集的数据集合并到join_train02进行训练，共18653张
  #------------------------车辆为圆心，螺旋飞行至半径增加不超过0.05m--------------------------
  car3_0000_3179_202:车辆左侧起飞，-2200  -4800  202  180°，高度3m，初始半径3.67m
  car3_3200_821_1.8:车辆左后方起飞，-2250  -5000  202  135°，高度3.8m，初始半径4.11m
  car3_3300_737_2.0:车辆左后方起飞，-2200  -5100  202  135°，高度4m，初始半径5.16m
  car3_4200_1007_2.3:车辆后方起飞，-2600  -5140  202  85°，高度4.3m，初始半径4.12m
  car3_5210_1105_2.5:车辆右后方起飞，-2900  -5000  202  40°，高度4.5m，初始半径4.34m
  car3_6320_877_3:车辆右侧起飞，-3200  -4700  202  0°，高度5m，初始半径6.4m
  car3_7200_620_3.5:车辆右侧起飞，-3500  -4700  202  0°，高度5.5m，初始半径9.4m
  car3_7900_659_4:车辆右侧起飞，-3600  -4700  202  0°，高度6m，初始半径10.4m
  car3_8580_1403_4.5:车辆右侧起飞，-3800  -4700  202  0°，高度6.5m，初始半径12.4m
  car3_30000_1009_1.7:车辆右侧起飞，-2900  -4700  202  0°，高度3.7m，初始半径3.4m
  #----------------------------固定朝向，与车辆平行飞行-------------------------------
  car3_31020_87_depth4.4:车辆右侧，-3000  -5000  202  0°，距离4.4m
  car3_31110_189_back5.7:车辆后方，-2100  -5300  202  90°，距离5.7m
  car3_31300_189_left5.6:车辆左侧，-2000  -4200  202  180°，距离5.6m
  car3_31500_194_front7.3:车辆前方，-3000 -4000  202  -90° ，距离7.3m 
  car3_31700_228_frontside75:车辆前方-3000  -4100  202  -75° ，右后方斜飞行，228张->证明标签x修改成功
  #------------------------改变圆心以及无人机朝向------------------------------------
  car3_32000_955_center1R:车辆左侧的右方向偏移1.7m，初始半径3.6m，高度3m，180°，955张图片
  car3_32960_902_center1L:车辆左侧的左方向偏移1.8m，初始半径3.6m，高度3m，180°，902张图片
  car3_33870_865_center2L:车辆前方的左方向偏移2m，初始半径4.3m，高度3m，-90°，865张图片
  car3_34740_869_center2R:车辆前方的右方向偏移2.3m，初始半径4.3m，高度3m，-90°，869张图片
  car3_35620_866_cr1.7_RL:车辆右侧的左方向偏移2.7m，初始半径5m，高度3.7m，0°，866张图片
  car3_36490_864_cr1.7_RR:车辆右侧的右方向偏移2.7m，初始半径5m，高度3.7m，0°，864张图片
  car3_37360_873_cr1.7_BL:车辆后方的左方向偏移1.6m，初始半径5.2m，高度3.7m，90°，873张图片
  car3_38240_876_cr1.7_BR:车辆后方的右方向偏移1.4m，初始半径5.2m，高度3.7m，90°，876张图片
  #-------------------------------------------------------------------------------------
  model_final：初始自带模型
  model_final_1415：车1和车3自采集数据训练--失败
  model_final_7481:使用原始7千数据从头开始训练
  model_final_12481：使用原始数据加车1的5005数据在原始参数基础上训练结果
  
  model_final_z7-16_18653.pth：7月16手动修正的一万张数据+标签修正的7957张数据
  model_final_z7_17_7957.pth：7月17标签修正后的7957数据，DETECT_CLASSES: ("Car",)30000代
  
  #-------------------------改进--------------------------------
  进行训练，60000次迭代，数据量充足，50%交叉验证，对于后续改进：
  1.寻找模型训练输出准确率
  2.模型只输入了car，对于其他label是否必要需要验证
  3.模型的其他参数是否需要修改，使用的什么网络进行训练等
  4.既然修正了标签标注，查看是否可以适当的数据增强
  5.如果已拥有可使用模型，对于后续的无人机控制算法写个大致框架
  
  # 7.21
  1.数据集中车辆不可以被截断和遮挡
  # 9.27（8.27）
  1.更改原始的7000多数据从多类到一类，查看训练效果
  2.查看数据的样本
  3.无人机控制
  4.将官方样本角度应用到仿真场景  控制变量训练模型
  
  
  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  
  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    Github token -2021-11-24
  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    2021-12-27
  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 Expires on Sat, Nov 27 2021.
  git config --global credential.helper store
  wcpmfnbakqhhbegj 
  ```

- **mono_3d代码阅读笔记**

  ```python
  1./home/wal/project/smoke_mono_3d/smoke/config/defaults.py : 修改阈值
  2.
  
  # -----------------------------------------------------------------------------------
  1.
  
  # -----------------------------------------------------------------------------------
  join02_files：严格圆心轨迹采集的一万左右数据+correct里标签算法改进后采集的四周和改变圆心采集的7千9百多数据  http://10.193.232.5/
  
  join_train02:严格根据join02_files汇总的数据集
  join_train03：仅使用标签算法改进的7千多数据
  join_train04：将改进算法采集的绕圈轨迹(6 8 10 12)修正截断值后汇总的数据集
  join_train05：将correct中数据集所有截断的样本删除
  join_train06：将03的所有数据修正截断值，截断值保留两位小数
  # -----------------------------------------------------------------------------------
  model_z0929_3559.pth：9月29日 6 8 10 12共3559个样本，人工标定了截断值进行训练
  model_z0930_6162.pth：9月30日将correct中数据集所有截断的样本删除后进行训练
  model_z1001_7957.pth：10月1日将03的所有数据修正截断值，截断值保留两位小数
  model_z1002_11040.pth：10月2日将粗略调整截断值的3559数据和7481官方数据结合训练6万次
  model_z1004_15438.pth：10.4将所有数据修正截断值和7481官方数据集一起训练10万次
  ```

- **9.28**

  ```python
  # 9.28
  将join02_files/correct里的绕圈旋转图片取第6 8 10 12个文件夹进行修改label，写了delete_data脚本，挨个显示图片，输入1-9代表0.1-0.9的截断，对于后半几圈飞行不存在截断的情况，给了iop三个按键分别代表跳过10 20 50个图片（直接shutil.copy） 共处理好3559个图片 今晚训练  后续再次训练7481个图片（0 0 0 0），然后删去其他类型再次训练
  ln -s /home/wal/Documents/AirSim/trainingwal/join_train04 datasets/kitti
  #效果：
  model_z0929_3559.pth  目测准确率七八十，有一定的效果，感觉方向对了，后面首先尝试把所有截断数据取消，纯无截断样本训练一次，然后增加截断数据，将四边的平移采集修改截断值训练一次，一定有收获。
  
  # 9.29
  将join_train03复制成05，写了dele函数来逐个删除截断样本，最后剩余6162个样本，晚上训练。
  #效果：
  很差  应该不能把样本中的截断数据全部删除
  
  # 9.30
  观察官方样本截断值标定情况，纪录在Files/3D/标签分析-截断值.docx中
  优化了TL.truncation()方法，每次输入数字时即可输入两位数字代表截断值，手动标定了7957中的大概2000张图片，现在样本数量上升且精度高一些同时含有截断数据。
  # 效果
  仅仅增加了数据量改善并不大，而且由于发现官方样本中截断值并不准确，在此次数据集中增加了截断值精确度变化也不大，但总体效果还是比完全去除截断数据好一些。准备将3559的数据集和官方数据集合并进行训练看看效果
  
  # 10.2
  将粗略调整截断值的3559数据和7481官方数据结合训练6万次，得到模型对仿真数据远距离情况识别准确度较好，对官方数据集识别情况下降很多
  
  # 10.4
  model_z1004_15438模型效果也比较差，观察输出loss（暂不知道怎么观察accuracy）发现loss在3万代左右loss变化就很小了，所有代数的增加优化并不大；在仿真软件中测试两个模型(11040和7481)效果，发现11040在7481的死角处效果较好，但有些部分识别角度误差比较大，官方模型也存在这个问题，所以暂时可以说此模型比官方模型在仿真环境中表现较优，对比视频以保存，可展示；最后粗略写了无人机自动检测此时位置选择绕圈方向，自动移动到车辆正前方停止飞行，视频以保存。
  ```
  
  